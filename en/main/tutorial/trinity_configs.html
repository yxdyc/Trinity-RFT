
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Configuration Guide &#8212; Trinity-RFT 0.4.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=183391d5"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorial/trinity_configs';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="GPU Configuration Guide" href="trinity_gpu_configs.html" />
    <link rel="prev" title="üß™ Experimental: Task Selection" href="develop_selector.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.svg" class="logo__image only-light" alt="Trinity-RFT 0.4.0 documentation - Home"/>
    <script>document.write(`<img src="../_static/logo.svg" class="logo__image only-dark" alt="Trinity-RFT 0.4.0 documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">
<nav class="bd-links bd-docs-nav">
    <div class="bd-toc-item navbar-nav">
        <ul class="nav bd-sidenav">
      <li class="toctree-l1 has-children">
        <details>
          <summary>
            <p class="caption" aria-level="2" role="heading" style="text-align: center;">
              <span class="fa fa-book"></span>
             <b>latest</b>
            </p>
          </summary>
          <ul>
            <li class="toctree-l2 current "><a class="reference" href="trinity_configs.html">latest</a></li>
          </ul>
        </details>
      </li>
    </ul>
    </div>
</nav>
</div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Guidelines</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="trinity_installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="develop_overview.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="develop_workflow.html">Workflow Development Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="develop_algorithm.html">Algorithms Development Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_mix_algo.html">Advanced Algorithm Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="develop_operator.html">Operator Development Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="develop_selector.html">üß™ Experimental: Task Selection</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Configuration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="trinity_gpu_configs.html">GPU Configuration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="synchronizer.html">Synchronizer in Trinity-RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="align_with_verl.html">Align configuration with veRL</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="example_reasoning_basic.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_reasoning_advanced.html">Off-Policy RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_async_mode.html">Asynchronous RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_multi_turn.html">Concatenated Multi-Turn RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_step_wise.html">General Multi-Step RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_react.html">ReAct Agent Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_search_email.html">Email Search Workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_dpo.html">Offline DPO and SFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_tinker_backend.html">Tinker Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_megatron.html">Megatron-LM Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_data_functionalities.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_dataset_perspective.html">Example Summary</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_reference.html">API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../build_api/trinity.buffer.html">trinity.buffer package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.buffer.operators.html">trinity.buffer.operators package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.operators.filters.html">trinity.buffer.operators.filters package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.operators.mappers.html">trinity.buffer.operators.mappers package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.operators.data_juicer_operator.html">trinity.buffer.operators.data_juicer_operator module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.operators.experience_operator.html">trinity.buffer.operators.experience_operator module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.buffer.pipelines.html">trinity.buffer.pipelines package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.pipelines.experience_pipeline.html">trinity.buffer.pipelines.experience_pipeline module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.pipelines.task_pipeline.html">trinity.buffer.pipelines.task_pipeline module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.buffer.reader.html">trinity.buffer.reader package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.reader.file_reader.html">trinity.buffer.reader.file_reader module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.reader.queue_reader.html">trinity.buffer.reader.queue_reader module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.reader.sql_reader.html">trinity.buffer.reader.sql_reader module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.buffer.schema.html">trinity.buffer.schema package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.schema.formatter.html">trinity.buffer.schema.formatter module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.schema.sql_schema.html">trinity.buffer.schema.sql_schema module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.buffer.selector.html">trinity.buffer.selector package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.selector.difficulty_estimator.html">trinity.buffer.selector.difficulty_estimator module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.selector.selector.html">trinity.buffer.selector.selector module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.buffer.storage.html">trinity.buffer.storage package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.storage.file.html">trinity.buffer.storage.file module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.storage.queue.html">trinity.buffer.storage.queue module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.storage.sql.html">trinity.buffer.storage.sql module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.buffer.writer.html">trinity.buffer.writer package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.writer.file_writer.html">trinity.buffer.writer.file_writer module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.writer.queue_writer.html">trinity.buffer.writer.queue_writer module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.buffer.writer.sql_writer.html">trinity.buffer.writer.sql_writer module</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.buffer.buffer.html">trinity.buffer.buffer module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.buffer.buffer_reader.html">trinity.buffer.buffer_reader module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.buffer.buffer_writer.html">trinity.buffer.buffer_writer module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.buffer.task_scheduler.html">trinity.buffer.task_scheduler module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.buffer.utils.html">trinity.buffer.utils module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.buffer.viewer.html">trinity.buffer.viewer module</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../build_api/trinity.explorer.html">trinity.explorer package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.explorer.proxy.html">trinity.explorer.proxy package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.explorer.proxy.app.html">trinity.explorer.proxy.app module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.explorer.proxy.client.html">trinity.explorer.proxy.client module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.explorer.proxy.recorder.html">trinity.explorer.proxy.recorder module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.explorer.proxy.service.html">trinity.explorer.proxy.service module</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.explorer.explorer.html">trinity.explorer.explorer module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.explorer.scheduler.html">trinity.explorer.scheduler module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.explorer.workflow_runner.html">trinity.explorer.workflow_runner module</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../build_api/trinity.trainer.html">trinity.trainer package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.trainer.tinker.html">trinity.trainer.tinker package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.trainer.tinker.utils.html">trinity.trainer.tinker.utils module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.trainer.verl.html">trinity.trainer.verl package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.trainer.verl.dp_actor.html">trinity.trainer.verl.dp_actor module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.trainer.verl.fsdp_checkpoint_manager.html">trinity.trainer.verl.fsdp_checkpoint_manager module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.trainer.verl.fsdp_workers.html">trinity.trainer.verl.fsdp_workers module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.trainer.verl.megatron_actor.html">trinity.trainer.verl.megatron_actor module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.trainer.verl.megatron_checkpoint_manager.html">trinity.trainer.verl.megatron_checkpoint_manager module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.trainer.verl.megatron_workers.html">trinity.trainer.verl.megatron_workers module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.trainer.verl.utils.html">trinity.trainer.verl.utils module</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.trainer.tinker_trainer.html">trinity.trainer.tinker_trainer module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.trainer.trainer.html">trinity.trainer.trainer module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.trainer.verl_trainer.html">trinity.trainer.verl_trainer module</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../build_api/trinity.algorithm.html">trinity.algorithm package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.html">trinity.algorithm.advantage_fn package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.advantage_fn.html">trinity.algorithm.advantage_fn.advantage_fn module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.asymre_advantage.html">trinity.algorithm.advantage_fn.asymre_advantage module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.grpo_advantage.html">trinity.algorithm.advantage_fn.grpo_advantage module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.multi_step_grpo_advantage.html">trinity.algorithm.advantage_fn.multi_step_grpo_advantage module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.on_policy_distill_advantage.html">trinity.algorithm.advantage_fn.on_policy_distill_advantage module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.opmd_advantage.html">trinity.algorithm.advantage_fn.opmd_advantage module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.ppo_advantage.html">trinity.algorithm.advantage_fn.ppo_advantage module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.rec_advantage.html">trinity.algorithm.advantage_fn.rec_advantage module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.reinforce_advantage.html">trinity.algorithm.advantage_fn.reinforce_advantage module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.reinforce_plus_plus_advantage.html">trinity.algorithm.advantage_fn.reinforce_plus_plus_advantage module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.remax_advantage.html">trinity.algorithm.advantage_fn.remax_advantage module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.advantage_fn.rloo_advantage.html">trinity.algorithm.advantage_fn.rloo_advantage module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.algorithm.entropy_loss_fn.html">trinity.algorithm.entropy_loss_fn package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.entropy_loss_fn.entropy_loss_fn.html">trinity.algorithm.entropy_loss_fn.entropy_loss_fn module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.algorithm.kl_fn.html">trinity.algorithm.kl_fn package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.kl_fn.kl_fn.html">trinity.algorithm.kl_fn.kl_fn module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.html">trinity.algorithm.policy_loss_fn package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.chord_policy_loss.html">trinity.algorithm.policy_loss_fn.chord_policy_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.cispo_policy_loss.html">trinity.algorithm.policy_loss_fn.cispo_policy_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.dpo_loss.html">trinity.algorithm.policy_loss_fn.dpo_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.gspo_policy_loss.html">trinity.algorithm.policy_loss_fn.gspo_policy_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.importance_sampling_policy_loss.html">trinity.algorithm.policy_loss_fn.importance_sampling_policy_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.mix_policy_loss.html">trinity.algorithm.policy_loss_fn.mix_policy_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.opmd_policy_loss.html">trinity.algorithm.policy_loss_fn.opmd_policy_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.policy_loss_fn.html">trinity.algorithm.policy_loss_fn.policy_loss_fn module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.ppo_policy_loss.html">trinity.algorithm.policy_loss_fn.ppo_policy_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.rec_policy_loss.html">trinity.algorithm.policy_loss_fn.rec_policy_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.sapo_policy_loss.html">trinity.algorithm.policy_loss_fn.sapo_policy_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.sft_loss.html">trinity.algorithm.policy_loss_fn.sft_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.sppo_loss_fn.html">trinity.algorithm.policy_loss_fn.sppo_loss_fn module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.policy_loss_fn.topr_policy_loss.html">trinity.algorithm.policy_loss_fn.topr_policy_loss module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.algorithm.sample_strategy.html">trinity.algorithm.sample_strategy package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.sample_strategy.mix_sample_strategy.html">trinity.algorithm.sample_strategy.mix_sample_strategy module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.sample_strategy.sample_strategy.html">trinity.algorithm.sample_strategy.sample_strategy module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.algorithm.sample_strategy.utils.html">trinity.algorithm.sample_strategy.utils module</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.algorithm.algorithm.html">trinity.algorithm.algorithm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.algorithm.key_mapper.html">trinity.algorithm.key_mapper module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.algorithm.utils.html">trinity.algorithm.utils module</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../build_api/trinity.manager.html">trinity.manager package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.manager.config_registry.html">trinity.manager.config_registry package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.manager.config_registry.algorithm_config_manager.html">trinity.manager.config_registry.algorithm_config_manager module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.manager.config_registry.buffer_config_manager.html">trinity.manager.config_registry.buffer_config_manager module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.manager.config_registry.config_registry.html">trinity.manager.config_registry.config_registry module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.manager.config_registry.explorer_config_manager.html">trinity.manager.config_registry.explorer_config_manager module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.manager.config_registry.model_config_manager.html">trinity.manager.config_registry.model_config_manager module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.manager.config_registry.trainer_config_manager.html">trinity.manager.config_registry.trainer_config_manager module</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.manager.config_manager.html">trinity.manager.config_manager module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.manager.state_manager.html">trinity.manager.state_manager module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.manager.synchronizer.html">trinity.manager.synchronizer module</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../build_api/trinity.common.html">trinity.common package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.common.models.html">trinity.common.models package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.models.vllm_patch.html">trinity.common.models.vllm_patch package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.models.mm_utils.html">trinity.common.models.mm_utils module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.models.model.html">trinity.common.models.model module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.models.tinker_model.html">trinity.common.models.tinker_model module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.models.utils.html">trinity.common.models.utils module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.models.vllm_model.html">trinity.common.models.vllm_model module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.models.vllm_worker.html">trinity.common.models.vllm_worker module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.common.rewards.html">trinity.common.rewards package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.accuracy_reward.html">trinity.common.rewards.accuracy_reward module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.agents_reward.html">trinity.common.rewards.agents_reward module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.countdown_reward.html">trinity.common.rewards.countdown_reward module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.dapo_reward.html">trinity.common.rewards.dapo_reward module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.eval_utils.html">trinity.common.rewards.eval_utils module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.format_reward.html">trinity.common.rewards.format_reward module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.human_reward.html">trinity.common.rewards.human_reward module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.math_reward.html">trinity.common.rewards.math_reward module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.naive_dapo_score.html">trinity.common.rewards.naive_dapo_score module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.qwen25_eval.html">trinity.common.rewards.qwen25_eval module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.reward_fn.html">trinity.common.rewards.reward_fn module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.tool_reward.html">trinity.common.rewards.tool_reward module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.rewards.utils.html">trinity.common.rewards.utils module</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../build_api/trinity.common.workflows.html">trinity.common.workflows package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.agentscope.html">trinity.common.workflows.agentscope package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.agentscope_workflow.html">trinity.common.workflows.agentscope_workflow module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.customized_math_workflows.html">trinity.common.workflows.customized_math_workflows module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.customized_toolcall_workflows.html">trinity.common.workflows.customized_toolcall_workflows module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.eval_workflow.html">trinity.common.workflows.eval_workflow module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.math_rm_workflow.html">trinity.common.workflows.math_rm_workflow module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.math_ruler_workflow.html">trinity.common.workflows.math_ruler_workflow module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.math_trainable_ruler_workflow.html">trinity.common.workflows.math_trainable_ruler_workflow module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.on_policy_distill_workflow.html">trinity.common.workflows.on_policy_distill_workflow module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.rubric_judge_workflow.html">trinity.common.workflows.rubric_judge_workflow module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.simple_mm_workflow.html">trinity.common.workflows.simple_mm_workflow module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.step_wise_workflow.html">trinity.common.workflows.step_wise_workflow module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../build_api/trinity.common.workflows.workflow.html">trinity.common.workflows.workflow module</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.common.config.html">trinity.common.config module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.common.constants.html">trinity.common.constants module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.common.experience.html">trinity.common.experience module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.common.verl_config.html">trinity.common.verl_config module</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../build_api/trinity.utils.html">trinity.utils package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.utils.annotations.html">trinity.utils.annotations module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.utils.distributed.html">trinity.utils.distributed module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.utils.dlc_utils.html">trinity.utils.dlc_utils module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.utils.log.html">trinity.utils.log module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.utils.lora_utils.html">trinity.utils.lora_utils module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.utils.monitor.html">trinity.utils.monitor module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.utils.plugin_loader.html">trinity.utils.plugin_loader module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.utils.registry.html">trinity.utils.registry module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../build_api/trinity.utils.timer.html">trinity.utils.timer module</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="header-extra-switchers" style="display:inline-flex; gap:.25rem; margin-left:.5rem; align-items:center;">
  <button id="lang-toggle-btn" class="btn btn-sm btn-outline-secondary" title="">
  <span id="lang-toggle-label"></span>
</button>
<script>
(function () {
  const btn = document.getElementById('lang-toggle-btn');
  const lab = document.getElementById('lang-toggle-label');
  if (!btn || !lab) return;

  const m = location.pathname.match(/^(.*\/)(en|zh)(\/.*)$/);

  const cur = m ? m[2] : 'en';
  if (cur === 'en') {
    lab.textContent = '‰∏≠';
    btn.title = 'ÂàáÊç¢Âà∞‰∏≠Êñá';
  } else {
    lab.textContent = 'EN';
    btn.title = 'Switch to English';
  }

  const targetHref = (function () {
    if (!m) return location.href;
    const other = cur === 'en' ? 'zh' : 'en';
    const suffix = m[3] || '/';
    return m[1] + other + suffix + location.search + location.hash;
  })();

  btn.addEventListener('click', function () {
    location.href = targetHref;
  });
})();
</script>
</div>



<div class="article-header-buttons">


<a href="https://github.com/modelscope/Trinity-RFT" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/tutorial/trinity_configs.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Configuration Guide</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#global-configuration">Global Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithm-configuration">Algorithm Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monitor-configuration">Monitor Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-configuration">Model Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cluster-configuration">Cluster Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#buffer-configuration">Buffer Configuration</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explorer-input">Explorer Input</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#trainer-input">Trainer Input</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#explorer-configuration">Explorer Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#synchronizer-configuration">Synchronizer Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trainer-configuration">Trainer Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#service-configuration">Service Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataprocessor-configuration">DataProcessor Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#log-configuration">Log Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stages-configuration">Stages Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#verl-trainer-configuration-advanced">veRL Trainer Configuration (Advanced)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-new-config-entries-for-the-config-generator-advanced">Adding New Config Entries for the Config Generator (Advanced)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-0-understanding-streamlit">Step 0: Understanding Streamlit</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-implement-new-config-entries">Step 1: Implement New Config Entries</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-integrating-new-parameters-into-config-manager-py">Step 2: Integrating New Parameters into <code class="docutils literal notranslate"><span class="pre">config_manager.py</span></code></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="configuration-guide">
<span id="id1"></span><h1>Configuration Guide<a class="headerlink" href="#configuration-guide" title="Link to this heading">#</a></h1>
<p>This section provides a detailed description of the configuration files used in <strong>Trinity-RFT</strong>.</p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<p>The configuration for <strong>Trinity-RFT</strong> is defined in a <code class="docutils literal notranslate"><span class="pre">YAML</span></code> file and organized into multiple sections based on different modules. Here‚Äôs an example of a basic configuration file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">project</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Trinity-RFT</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">example</span>
<span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">both</span>
<span class="nt">checkpoint_root_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:TRINITY_CHECKPOINT_ROOT_DIR,./checkpoints}</span>
<span class="nt">continue_from_checkpoint</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>

<span class="nt">algorithm</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Algorithm-related parameters</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="nt">model</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Model-specific configurations</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="nt">cluster</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Cluster node and GPU settings</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="nt">buffer</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Data buffer configurations</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="nt">explorer</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Explorer-related settings (rollout models, workflow runners)</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="nt">trainer</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Trainer-specific parameters</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="nt">synchronizer</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Model weight synchronization settings</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="nt">monitor</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Monitoring configurations (e.g., WandB, TensorBoard or MLFlow)</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="nt">service</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Services to use</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="nt">data_processor</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Preprocessing data settings</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="nt">log</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Ray actor logging</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>

<span class="nt">stages</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Stages configuration</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
</pre></div>
</div>
<p>Each of these sections will be explained in detail below. For additional details about specific parameters not covered here, please refer to the <a class="reference external" href="https://github.com/modelscope/Trinity-RFT/blob/main/trinity/common/config.py">source code</a>.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Trinity-RFT uses <a class="reference external" href="https://omegaconf.readthedocs.io/en/latest/">OmegaConf</a> to load YAML configuration files.
It supports some advanced features like <a class="reference external" href="https://omegaconf.readthedocs.io/en/latest/usage.html#variable-interpolation">variable interpolation</a> and  <a class="reference external" href="https://omegaconf.readthedocs.io/en/latest/custom_resolvers.html#oc-env">environment variable substitution</a>.
Users can use these features to simplify configuration.</p>
</div>
</section>
<hr class="docutils" />
<section id="global-configuration">
<h2>Global Configuration<a class="headerlink" href="#global-configuration" title="Link to this heading">#</a></h2>
<p>These are general settings that apply to the entire experiment.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">project</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Trinity-RFT</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">example</span>
<span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">both</span>
<span class="nt">checkpoint_root_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:TRINITY_CHECKPOINT_ROOT_DIR,./checkpoints}</span><span class="w">   </span><span class="c1"># TRINITY_CHECKPOINT_ROOT_DIR is an environment variable set in advance</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">project</span></code>: The name of the project.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: The name of the current experiment.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mode</span></code>: Running mode of Trinity-RFT. Options include:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">both</span></code>: Launches both the trainer and explorer (default).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train</span></code>: Only launches the trainer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">explore</span></code>: Only launches the explorer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bench</span></code>: Used for benchmarking.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">checkpoint_root_dir</span></code>: Root directory where all checkpoints and logs will be saved. Checkpoints for this experiment will be stored in <code class="docutils literal notranslate"><span class="pre">&lt;checkpoint_root_dir&gt;/&lt;project&gt;/&lt;name&gt;/</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">continue_from_checkpoint</span></code>: If set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, the experiment will continue from the latest checkpoint in the checkpoint path (if any); otherwise, it will rename the current experiment to <code class="docutils literal notranslate"><span class="pre">&lt;name&gt;_&lt;timestamp&gt;</span></code> and start a new experiment. Due to our decoupled design, during recovery from a checkpoint, we can only guarantee that the Trainer‚Äôs model parameters and its optional auxiliary buffers (<code class="docutils literal notranslate"><span class="pre">auxiliary_buffers</span></code>) are restored to their latest checkpointed states, while the Explorer and Experience Buffer cannot be guaranteed to be restored to the same point in time.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ray_namespace</span></code>: Namespace for the modules launched in the current experiment. If not specified, it will be set to <code class="docutils literal notranslate"><span class="pre">&lt;project&gt;/&lt;name&gt;</span></code>.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="algorithm-configuration">
<h2>Algorithm Configuration<a class="headerlink" href="#algorithm-configuration" title="Link to this heading">#</a></h2>
<p>Specifies the algorithm type and its related hyperparameters.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">algorithm</span><span class="p">:</span>
<span class="w">  </span><span class="nt">algorithm_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">grpo</span>
<span class="w">  </span><span class="nt">repeat_times</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">  </span><span class="nt">optimizer</span><span class="p">:</span>
<span class="w">    </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-6</span>
<span class="w">    </span><span class="nt">warmup_style</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;warmup&quot;</span>
<span class="w">  </span><span class="c1"># The following parameters are optional</span>
<span class="w">  </span><span class="c1"># If not specified, they will automatically be set based on the `algorithm_type`</span>
<span class="w">  </span><span class="nt">sample_strategy</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;default&quot;</span>
<span class="w">  </span><span class="nt">advantage_fn</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;ppo&quot;</span>
<span class="w">  </span><span class="nt">kl_penalty_fn</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;none&quot;</span>
<span class="w">  </span><span class="nt">kl_loss_fn</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;k2&quot;</span>
<span class="w">  </span><span class="nt">entropy_loss_fn</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;default&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">algorithm_type</span></code>: Type of reinforcement learning algorithm. Supported types: <code class="docutils literal notranslate"><span class="pre">ppo</span></code>, <code class="docutils literal notranslate"><span class="pre">grpo</span></code>, <code class="docutils literal notranslate"><span class="pre">opmd</span></code>, <code class="docutils literal notranslate"><span class="pre">dpo</span></code>, <code class="docutils literal notranslate"><span class="pre">sft</span></code>, <code class="docutils literal notranslate"><span class="pre">mix</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">repeat_times</span></code>: Number of times each task is repeated. Default is <code class="docutils literal notranslate"><span class="pre">1</span></code>. In <code class="docutils literal notranslate"><span class="pre">dpo</span></code>, this is automatically set to <code class="docutils literal notranslate"><span class="pre">2</span></code>. Some algorithms such as GRPO and OPMD require <code class="docutils literal notranslate"><span class="pre">repeat_times</span></code> &gt; 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizer</span></code>: Optimizer configuration for actor.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">lr</span></code>: Learning rate for actor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">warmup_style</span></code>: Warmup style for actor‚Äôs learning rate.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample_strategy</span></code>: The sampling strategy used for loading experiences from experience buffer. Supported types: <code class="docutils literal notranslate"><span class="pre">default</span></code>, <code class="docutils literal notranslate"><span class="pre">staleness_control</span></code>, <code class="docutils literal notranslate"><span class="pre">mix</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">advantage_fn</span></code>: The advantage function used for computing advantages.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kl_penalty_fn</span></code>: The KL penalty function used for computing KL penalty applied in reward.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kl_loss_fn</span></code>: The KL loss function used for computing KL loss.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy_loss_fn</span></code>: The entropy loss function used for computing entropy loss.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="monitor-configuration">
<h2>Monitor Configuration<a class="headerlink" href="#monitor-configuration" title="Link to this heading">#</a></h2>
<p>Used to log training metrics during execution.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">monitor</span><span class="p">:</span>
<span class="w">  </span><span class="nt">monitor_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wandb</span>
<span class="w">  </span><span class="nt">monitor_args</span><span class="p">:</span>
<span class="w">    </span><span class="nt">base_url</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">http://localhost:8080</span>
<span class="w">    </span><span class="nt">api_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">your_api_key</span>
<span class="w">  </span><span class="nt">enable_ray_timeline</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">monitor_type</span></code>: Type of monitoring system. Options:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">wandb</span></code>: Logs to <a class="reference external" href="https://docs.wandb.ai/quickstart/">Weights &amp; Biases</a>. Requires logging in and setting <code class="docutils literal notranslate"><span class="pre">WANDB_API_KEY</span></code>. Project and run names match the <code class="docutils literal notranslate"><span class="pre">project</span></code> and <code class="docutils literal notranslate"><span class="pre">name</span></code> fields in global configs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tensorboard</span></code>: Logs to <a class="reference external" href="https://www.tensorflow.org/tensorboard">TensorBoard</a>. Files are saved under <code class="docutils literal notranslate"><span class="pre">&lt;checkpoint_root_dir&gt;/&lt;project&gt;/&lt;name&gt;/monitor/tensorboard</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mlflow</span></code>: Logs to <a class="reference external" href="https://mlflow.org/">MLFlow</a>. If <a class="reference external" href="https://mlflow.org/docs/latest/ml/auth/">MLFlow authentication</a> is setup, set <code class="docutils literal notranslate"><span class="pre">MLFLOW_TRACKING_USERNAME</span></code> and <code class="docutils literal notranslate"><span class="pre">MLFLOW_TRACKING_PASSWORD</span></code> as environment variables before running.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">monitor_args</span></code>: Dictionary of arguments for monitor initialization.</p>
<ul>
<li><p>For <code class="docutils literal notranslate"><span class="pre">wandb</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">base_url</span></code>: Overrides <code class="docutils literal notranslate"><span class="pre">WANDB_BASE_URL</span></code> if set.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">api_key</span></code>: Overrides <code class="docutils literal notranslate"><span class="pre">WANDB_API_KEY</span></code> if set.</p></li>
</ul>
</li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">mlflow</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">uri</span></code>: The URI of your MLFlow instance. Strongly recommended to set; defaults to <code class="docutils literal notranslate"><span class="pre">http://localhost:5000</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">username</span></code>: Overrides <code class="docutils literal notranslate"><span class="pre">MLFLOW_TRACKING_USERNAME</span></code> if set.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">password</span></code>: Overrides <code class="docutils literal notranslate"><span class="pre">MLFLOW_TRACKING_PASSWORD</span></code> if set.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">enable_ray_timeline</span></code>: If <code class="docutils literal notranslate"><span class="pre">True</span></code>, exports a <code class="docutils literal notranslate"><span class="pre">timeline.json</span></code> file to <code class="docutils literal notranslate"><span class="pre">&lt;checkpoint_root_dir&gt;/&lt;project&gt;/&lt;name&gt;/monitor</span></code>. Viewable in Chrome at <a class="reference internal" href="#chrome://tracing"><span class="xref myst">chrome://tracing</span></a>.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="model-configuration">
<h2>Model Configuration<a class="headerlink" href="#model-configuration" title="Link to this heading">#</a></h2>
<p>Defines the model paths and token limits.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">model</span><span class="p">:</span>
<span class="w">  </span><span class="nt">model_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:MODEL_PATH}</span><span class="w">  </span><span class="c1"># MODEL_PATH is an environment variable set in advance</span>
<span class="w">  </span><span class="nt">critic_model_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${model.model_path}</span><span class="w">  </span><span class="c1"># use the value of model.model_path</span>
<span class="w">  </span><span class="nt">custom_chat_template</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">None</span>
<span class="w">  </span><span class="nt">chat_template_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">None</span>
<span class="w">  </span><span class="nt">max_model_len</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20480</span>
<span class="w">  </span><span class="nt">max_prompt_tokens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4096</span>
<span class="w">  </span><span class="nt">max_response_tokens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16384</span>
<span class="w">  </span><span class="nt">min_response_tokens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">enable_prompt_truncation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">  </span><span class="nt">repetition_penalty</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">  </span><span class="nt">lora_configs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">  </span><span class="nt">rope_scaling</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">  </span><span class="nt">rope_theta</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">  </span><span class="nt">tinker</span><span class="p">:</span>
<span class="w">    </span><span class="nt">enable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">rank</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">32</span>
<span class="w">    </span><span class="nt">seed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">train_mlp</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">train_attn</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">train_unembed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model_path</span></code>: Path to the model being trained. If <code class="docutils literal notranslate"><span class="pre">tinker</span></code> is enabled, this is the path to the local tokenizer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">critic_model_path</span></code>: Optional path to a separate critic model. If empty, defaults to <code class="docutils literal notranslate"><span class="pre">model_path</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">custom_chat_template</span></code>: Optional custom chat template in string format. If not specified, the system will use the default chat template from tokenizer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">chat_template_path</span></code>: Optional path to the chat template file in jinja2 type; overrides <code class="docutils literal notranslate"><span class="pre">custom_chat_template</span></code> if set. If not specified, the system will use the default chat template from tokenizer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_model_len</span></code>: Maximum number of tokens in a sequence. It is recommended to set this value manually. If not specified, the system will attempt to set it to <code class="docutils literal notranslate"><span class="pre">max_prompt_tokens</span></code> + <code class="docutils literal notranslate"><span class="pre">max_response_tokens</span></code>. However, this requires both values to be already set; otherwise, an error will be raised.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_response_tokens</span></code>: Maximum number of tokens allowed in generated responses. Only for <code class="docutils literal notranslate"><span class="pre">chat</span></code> and <code class="docutils literal notranslate"><span class="pre">generate</span></code> methods in <code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_prompt_tokens</span></code>: Maximum number of tokens allowed in prompts. Only for <code class="docutils literal notranslate"><span class="pre">chat</span></code> and <code class="docutils literal notranslate"><span class="pre">generate</span></code> methods in <code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_response_tokens</span></code>: Minimum number of tokens allowed in generated responses. Only for <code class="docutils literal notranslate"><span class="pre">chat</span></code> and <code class="docutils literal notranslate"><span class="pre">generate</span></code> methods in <code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">1</span></code>. It must be less than <code class="docutils literal notranslate"><span class="pre">max_response_tokens</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">enable_prompt_truncation</span></code>: Whether to truncate the prompt. Default is <code class="docutils literal notranslate"><span class="pre">true</span></code>. If set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, the prompt will be truncated to <code class="docutils literal notranslate"><span class="pre">max_prompt_tokens</span></code> tokens; if set to <code class="docutils literal notranslate"><span class="pre">false</span></code>, the prompt will not be truncated and there is a risk that the prompt length plus response length exceeds <code class="docutils literal notranslate"><span class="pre">max_model_len</span></code>. This function does not work with openai api mode.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">repetition_penalty</span></code>: Repetition penalty factor. Default is <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lora_configs</span></code>: Optional LoRA configuration. If not specified, defaults to <code class="docutils literal notranslate"><span class="pre">null</span></code>. Currently, only one LoRA configuration is supported, and this configuration will not be applied if <code class="docutils literal notranslate"><span class="pre">tinker</span></code> is enabled.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: Name of the LoRA. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: Path to the LoRA. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">base_model_name</span></code>: Name of the base model for LoRA. If not specified, defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lora_rank</span></code>: Rank of the LoRA. Default is <code class="docutils literal notranslate"><span class="pre">32</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lora_alpha</span></code>: Alpha value of the LoRA. Default is <code class="docutils literal notranslate"><span class="pre">32</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lora_dtype</span></code>: Data type of the LoRA. Default is <code class="docutils literal notranslate"><span class="pre">auto</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">target_modules</span></code>: List of target modules for LoRA. Default is <code class="docutils literal notranslate"><span class="pre">all-linear</span></code>.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">rope_scaling</span></code>: Optional RoPE scaling configuration in JSON format. If not specified, defaults to <code class="docutils literal notranslate"><span class="pre">null</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rope_theta</span></code>: Optional RoPE theta value. If not specified, defaults to <code class="docutils literal notranslate"><span class="pre">null</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tinker</span></code>: Optional Tinker configuration. Note: LoRA configuration will be ignored if Tinker is enabled.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">enable</span></code>: Whether to enable Tinker. Default is <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rank</span></code>: LoRA rank controlling the size of adaptation matrices. Default is <code class="docutils literal notranslate"><span class="pre">32</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">seed</span></code>: Random seed for Tinker. If not specified, defaults to <code class="docutils literal notranslate"><span class="pre">null</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_mlp</span></code>: Whether to train the MLP layer. Default is <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_attn</span></code>: Whether to train the attention layer. Default is <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_unembed</span></code>: Whether to train the unembedding layer. Default is <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p></li>
</ul>
</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you are using the openai API provided by Explorer, only <code class="docutils literal notranslate"><span class="pre">max_model_len</span></code> will take effect, and the value of <code class="docutils literal notranslate"><span class="pre">max_response_tokens</span></code>, <code class="docutils literal notranslate"><span class="pre">max_prompt_tokens</span></code>, and <code class="docutils literal notranslate"><span class="pre">min_response_tokens</span></code> will be ignored. When <code class="docutils literal notranslate"><span class="pre">max_tokens</span></code> is not independently specified, each API call will generate up to <code class="docutils literal notranslate"><span class="pre">max_model_len</span> <span class="pre">-</span> <span class="pre">prompt_length</span></code> tokens. Therefore, please ensure that the prompt length is less than <code class="docutils literal notranslate"><span class="pre">max_model_len</span></code> when using the API.</p>
</div>
</section>
<hr class="docutils" />
<section id="cluster-configuration">
<h2>Cluster Configuration<a class="headerlink" href="#cluster-configuration" title="Link to this heading">#</a></h2>
<p>Defines how many nodes and GPUs per node are used.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">cluster</span><span class="p">:</span>
<span class="w">  </span><span class="nt">node_num</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">gpu_per_node</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">node_num</span></code>: Total number of compute nodes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gpu_per_node</span></code>: Number of GPUs available per node.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="buffer-configuration">
<h2>Buffer Configuration<a class="headerlink" href="#buffer-configuration" title="Link to this heading">#</a></h2>
<p>Configures the data buffers used by the explorer and trainer.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">buffer</span><span class="p">:</span>
<span class="w">  </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">32</span>
<span class="w">  </span><span class="nt">train_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">  </span><span class="nt">total_epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100</span>
<span class="w">  </span><span class="nt">total_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>

<span class="w">  </span><span class="nt">explorer_input</span><span class="p">:</span>
<span class="w">    </span><span class="nt">taskset</span><span class="p">:</span>
<span class="w">      </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">    </span><span class="nt">eval_tasksets</span><span class="p">:</span>
<span class="w">      </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">trainer_input</span><span class="p">:</span>
<span class="w">    </span><span class="nt">experience_buffer</span><span class="p">:</span>
<span class="w">      </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">    </span><span class="nt">auxiliary_buffers</span><span class="p">:</span>
<span class="w">      </span><span class="nt">buffer_1</span><span class="p">:</span>
<span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">      </span><span class="nt">buffer_2</span><span class="p">:</span>
<span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">...</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code>: Number of tasks used per training step. <em>Please do not multiply this value by the <code class="docutils literal notranslate"><span class="pre">algorithm.repeat_times</span></code> manually</em>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_batch_size</span></code>: Number of experiences used per training step. Defaults to <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> * <code class="docutils literal notranslate"><span class="pre">algorithm.repeat_times</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">total_epochs</span></code>: Total number of training epochs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">total_steps</span></code>: Optional. The total number of training steps. If specified, <code class="docutils literal notranslate"><span class="pre">total_epochs</span></code> will be ignored.</p></li>
</ul>
<section id="explorer-input">
<h3>Explorer Input<a class="headerlink" href="#explorer-input" title="Link to this heading">#</a></h3>
<p>Defines the dataset(s) used by the explorer for training and evaluation.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">buffer</span><span class="p">:</span>
<span class="w">  </span><span class="nt">explorer_input</span><span class="p">:</span>
<span class="w">    </span><span class="nt">default_workflow_type</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;math_workflow&#39;</span>
<span class="w">    </span><span class="nt">default_eval_workflow_type</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;math_workflow&#39;</span>
<span class="w">    </span><span class="nt">default_reward_fn_type</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;countdown_reward&#39;</span>
<span class="w">    </span><span class="nt">taskset</span><span class="p">:</span>
<span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">countdown_train</span>
<span class="w">      </span><span class="nt">storage_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">file</span>
<span class="w">      </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:TRINITY_TASKSET_PATH}</span>
<span class="w">      </span><span class="nt">split</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">train</span>
<span class="w">      </span><span class="nt">format</span><span class="p">:</span>
<span class="w">        </span><span class="nt">prompt_key</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;question&#39;</span>
<span class="w">        </span><span class="nt">response_key</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;answer&#39;</span>
<span class="w">      </span><span class="nt">rollout_args</span><span class="p">:</span>
<span class="w">        </span><span class="nt">temperature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">      </span><span class="nt">default_workflow_type</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;math_workflow&#39;</span>
<span class="w">      </span><span class="nt">default_reward_fn_type</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;countdown_reward&#39;</span>

<span class="w">    </span><span class="nt">eval_tasksets</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">countdown_eval</span>
<span class="w">      </span><span class="nt">storage_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">file</span>
<span class="w">      </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:TRINITY_TASKSET_PATH}</span>
<span class="w">      </span><span class="nt">split</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">test</span>
<span class="w">      </span><span class="nt">repeat_times</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">      </span><span class="nt">format</span><span class="p">:</span>
<span class="w">        </span><span class="nt">prompt_type</span><span class="p">:</span><span class="w"> </span><span class="err">`</span><span class="l l-Scalar l-Scalar-Plain">plaintext`</span>
<span class="w">        </span><span class="nt">prompt_key</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;question&#39;</span>
<span class="w">        </span><span class="nt">response_key</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;answer&#39;</span>
<span class="w">      </span><span class="nt">rollout_args</span><span class="p">:</span>
<span class="w">        </span><span class="nt">temperature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">      </span><span class="nt">default_workflow_type</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;math_workflow&#39;</span>
<span class="w">      </span><span class="nt">default_reward_fn_type</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;countdown_reward&#39;</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">...</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">buffer.explorer_input.taskset</span></code>: Task dataset used for training exploration policies.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">buffer.explorer_input.eval_tasksets</span></code>: List of task datasets used for evaluation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">buffer.explorer_input.default_workflow_type</span></code>: Default workflow type for all task datasets under <code class="docutils literal notranslate"><span class="pre">explorer_input</span></code> if not specified at the dataset level.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">buffer.explorer_input.default_eval_workflow_type</span></code>: Default evaluation workflow type for all eval task datasets under <code class="docutils literal notranslate"><span class="pre">explorer_input</span></code> if not specified at the dataset level.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">buffer.explorer_input.default_reward_fn_type</span></code>: Default reward function type for all task datasets under <code class="docutils literal notranslate"><span class="pre">explorer_input</span></code> if not specified at the dataset level.</p></li>
</ul>
<p>The configuration for each task dataset is defined as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: Name of the dataset. This name will be used as the Ray actor‚Äôs name, so it must be unique.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">storage_type</span></code>: How the dataset is stored. Options: <code class="docutils literal notranslate"><span class="pre">file</span></code>, <code class="docutils literal notranslate"><span class="pre">queue</span></code>, <code class="docutils literal notranslate"><span class="pre">sql</span></code>.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">file</span></code>: The dataset is stored in <code class="docutils literal notranslate"><span class="pre">jsonl</span></code>/<code class="docutils literal notranslate"><span class="pre">parquet</span></code> files. The data file organization is required to meet the huggingface standard. <em>We recommand using this storage type for most cases.</em></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sql</span></code>: The dataset is stored in a SQL database. <em>This type is unstable and will be optimized in the future versions.</em></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: The path to the task dataset.</p>
<ul>
<li><p>For <code class="docutils literal notranslate"><span class="pre">file</span></code> storage type, the path points to the directory that contains the task dataset files. It supports loading both local and remote data files in a compatible format with <a class="reference external" href="https://huggingface.co/docs/datasets/main/en/package_reference/loading_methods#datasets.load_dataset"><code class="docutils literal notranslate"><span class="pre">datasets.load_dataset()</span></code></a> function.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">sql</span></code> storage type, the path points to the sqlite database file.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">subset_name</span></code>: The subset name of the task dataset, corresponding to the <code class="docutils literal notranslate"><span class="pre">name</span></code> parameter in huggingface datasets <code class="docutils literal notranslate"><span class="pre">load_dataset</span></code> function. Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">split</span></code>: The split of the task dataset, corresponding to the <code class="docutils literal notranslate"><span class="pre">split</span></code> parameter in huggingface datasets <code class="docutils literal notranslate"><span class="pre">load_dataset</span></code> function. Default is <code class="docutils literal notranslate"><span class="pre">train</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">repeat_times</span></code>: The number of rollouts generated for a task. If not set, it will be automatically set to <code class="docutils literal notranslate"><span class="pre">algorithm.repeat_times</span></code> for <code class="docutils literal notranslate"><span class="pre">taskset</span></code>, and <code class="docutils literal notranslate"><span class="pre">1</span></code> for <code class="docutils literal notranslate"><span class="pre">eval_tasksets</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rollout_args</span></code>: The parameters for rollout.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">temperature</span></code>: The temperature for sampling.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">default_workflow_type</span></code>: Type of workflow logic applied to this dataset. If not specified, the <code class="docutils literal notranslate"><span class="pre">buffer.default_workflow_type</span></code> is used.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">default_reward_fn_type</span></code>: Reward function used during exploration. If not specified, the <code class="docutils literal notranslate"><span class="pre">buffer.default_reward_fn_type</span></code> is used.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">workflow_args</span></code>: A dictionary of arguments used to supplement dataset-level parameters.</p></li>
</ul>
</section>
<section id="trainer-input">
<h3>Trainer Input<a class="headerlink" href="#trainer-input" title="Link to this heading">#</a></h3>
<p>Defines the experience buffer and optional auxiliary datasets used by the trainer.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">buffer</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">trainer_input</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="nt">experience_buffer</span><span class="p">:</span>
<span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">countdown_buffer</span>
<span class="w">      </span><span class="nt">storage_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">queue</span>
<span class="w">      </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sqlite:///countdown_buffer.db</span>
<span class="w">      </span><span class="nt">max_read_timeout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1800</span>

<span class="w">    </span><span class="nt">auxiliary_buffers</span><span class="p">:</span>
<span class="w">      </span><span class="nt">sft_dataset</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sft_dataset</span>
<span class="w">        </span><span class="nt">storage_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">file</span>
<span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:TRINITY_SFT_DATASET_PATH}</span>
<span class="w">        </span><span class="nt">format</span><span class="p">:</span>
<span class="w">          </span><span class="nt">prompt_key</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;question&#39;</span>
<span class="w">          </span><span class="nt">response_key</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;answer&#39;</span>
<span class="w">      </span><span class="nt">other_buffer</span><span class="p">:</span>
<span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">...</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">experience_buffer</span></code>: It is the input of Trainer and also the output of Explorer. This field is required even in explore mode.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: The name of the experience buffer. This name will be used as the Ray actor‚Äôs name, so it must be unique.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">storage_type</span></code>: The storage type for the experience buffer.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">queue</span></code>: Experience data is stored in a queue. This storage type is recommended for most use cases.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sql</span></code>: Experience data is stored in a SQL database.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">file</span></code>: Experience data is stored in a JSON file. This storage type should be used only for debugging purposes in <code class="docutils literal notranslate"><span class="pre">explore</span></code> mode.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>: The path to the experience buffer.</p>
<ul>
<li><p>For <code class="docutils literal notranslate"><span class="pre">queue</span></code> storage type, this field is optional. You can specify a SQLite database or JSON file path here to back up the queue data.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">file</span></code> storage type, the path points to the directory containing the dataset files.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">sql</span></code> storage type, the path points to the SQLite database file.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">format</span></code>: Mainly for SFT and DPO algorithm datasets, used to format the extracted data.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">prompt_type</span></code>: Specifies the type of prompts in the dataset. We support <code class="docutils literal notranslate"><span class="pre">plaintext</span></code>, <code class="docutils literal notranslate"><span class="pre">messages</span></code> for now.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">plaintext</span></code>: The prompt is in string format.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">messages</span></code>: The prompt is organized as a message list.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">prompt_key</span></code>: Specifies which column in the dataset contains the user prompt data. Only for <code class="docutils literal notranslate"><span class="pre">plaintext</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">response_key</span></code>: Specifies which column in the dataset contains the response data. Only for <code class="docutils literal notranslate"><span class="pre">plaintext</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">system_prompt_key</span></code>: Specifies which column in the dataset contains the system prompt data. Only for <code class="docutils literal notranslate"><span class="pre">plaintext</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">system_prompt</span></code>: Specifies the system prompt in string format. It has lower priority than <code class="docutils literal notranslate"><span class="pre">system_prompt_key</span></code>. Only for <code class="docutils literal notranslate"><span class="pre">plaintext</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">messages_key</span></code>: Specifies which column in the dataset contains the messages data. Only for <code class="docutils literal notranslate"><span class="pre">messages</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tools_key</span></code>: Specifies which column in the dataset contains the tools data. Support both <code class="docutils literal notranslate"><span class="pre">plaintext</span></code> and <code class="docutils literal notranslate"><span class="pre">messages</span></code>, but the tool data should be organized as a list of dict.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">chosen_key</span></code>: Specifies which column in the dataset contains the DPO chosen data. Support both <code class="docutils literal notranslate"><span class="pre">plaintext</span></code> and <code class="docutils literal notranslate"><span class="pre">messages</span></code>, and the data type should be consistent with the prompt type.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rejected_key</span></code>: Similar to <code class="docutils literal notranslate"><span class="pre">chosen_key</span></code>, but it specifies which column in the dataset contains the DPO rejected data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">enable_concatenated_multi_turn</span></code>: Enable concatenated multi-turn SFT data preprocess. Only for <code class="docutils literal notranslate"><span class="pre">messages</span></code> and only take effect with SFT algorithm.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">chat_template</span></code>: Specifies the chat template in string format. If not provided, use <code class="docutils literal notranslate"><span class="pre">model.custom_chat_template</span></code>.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_read_timeout</span></code>: The maximum waiting time (in seconds) to read new experience data. If exceeded, an incomplete batch will be returned directly. Only take effect when <code class="docutils literal notranslate"><span class="pre">storage_type</span></code> is <code class="docutils literal notranslate"><span class="pre">queue</span></code>. Default is 1800 seconds (30 minutes).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">replay_buffer</span></code>: Only take effect when <code class="docutils literal notranslate"><span class="pre">storage_type</span></code> is <code class="docutils literal notranslate"><span class="pre">queue</span></code>. Used to configure the replay buffer for experience reuse.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">enable</span></code>: Whether to enable the replay buffer. Default is <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reuse_cooldown_time</span></code>: Cooldown time (in seconds) for reusing experiences. If not specified, the default value is <code class="docutils literal notranslate"><span class="pre">None</span></code>, meaning experiences can not be reused.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">priority_fn</span></code>: Experience priority function used to determine the order of experience reuse. Currently supports <code class="docutils literal notranslate"><span class="pre">linear_decay</span></code> and <code class="docutils literal notranslate"><span class="pre">linear_decay_use_count_control_randomization</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">priority_fn_args</span></code>: A dictionary of arguments passed to the priority function, specific parameters depend on the selected priority function.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">auxiliary_buffers</span></code>: Optional buffers used for trainer. It is a dictionary where each key is the buffer name and the value is the buffer configuration. Each buffer configuration is similar to the <code class="docutils literal notranslate"><span class="pre">experience_buffer</span></code>.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="explorer-configuration">
<h2>Explorer Configuration<a class="headerlink" href="#explorer-configuration" title="Link to this heading">#</a></h2>
<p>Controls the rollout models and workflow execution.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">explorer</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">explorer</span>
<span class="w">  </span><span class="nt">runner_per_model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">  </span><span class="nt">max_timeout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">900</span>
<span class="w">  </span><span class="nt">max_retry_times</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">  </span><span class="nt">env_vars</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{}</span>
<span class="w">  </span><span class="nt">rollout_model</span><span class="p">:</span>
<span class="w">    </span><span class="nt">engine_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">vllm</span>
<span class="w">    </span><span class="nt">engine_num</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">tensor_parallel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">enable_history</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">  </span><span class="nt">auxiliary_models</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">model_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Qwen/Qwen2.5-7B-Instruct</span>
<span class="w">    </span><span class="nt">tensor_parallel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">eval_interval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100</span>
<span class="w">  </span><span class="nt">eval_on_startup</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">  </span><span class="nt">over_rollout</span><span class="p">:</span>
<span class="w">    </span><span class="nt">ratio</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">    </span><span class="nt">wait_after_min</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">30.0</span>
<span class="w">  </span><span class="nt">dynamic_timeout</span><span class="p">:</span>
<span class="w">    </span><span class="nt">enable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">ratio</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3.0</span>
<span class="w">  </span><span class="nt">runner_state_report_interval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: Name of the explorer. This name will be used as the Ray actor‚Äôs name, so it must be unique.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">runner_per_model</span></code>: Number of parallel workflow runners per each rollout model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_timeout</span></code>: Maximum time (in seconds) for a workflow to complete.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_retry_times</span></code>: Maximum number of retries for a workflow.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">env_vars</span></code>: Environment variables to be set for every workflow runners.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rollout_model.engine_type</span></code>: Type of inference engine. For now, only <code class="docutils literal notranslate"><span class="pre">vllm_async</span></code> and <code class="docutils literal notranslate"><span class="pre">vllm</span></code> is supported, they have the same meaning and both use the asynchronous engine. In subsequent versions, only <code class="docutils literal notranslate"><span class="pre">vllm</span></code> may be retained for simplicity.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rollout_model.engine_num</span></code>: Number of inference engines.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rollout_model.tensor_parallel_size</span></code>: Degree of tensor parallelism.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rollout_model.enable_history</span></code>: Whether to enable model call history recording. If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the model wrapper automatically records the return experiences of model calls. Please periodically extract the history via <code class="docutils literal notranslate"><span class="pre">extract_experience_from_history</span></code> to avoid out-of-memory issues. Default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">auxiliary_models</span></code>: Additional models used for custom workflows.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eval_interval</span></code>: Interval (in steps) for evaluating the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eval_on_startup</span></code>: Whether to evaluate the model on startup. More precisely, at step 0 with the original model, so it will not be triggered when restarting.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">over_rollout</span></code>: [Experimental] Configurations for over-rollout mechanism, which allows the explorer to proceed with fewer tasks than the full batch size. It effectively increases throughput in scenarios where some tasks take significantly longer to complete than others. Only applicable when dynamic synchronization (<code class="docutils literal notranslate"><span class="pre">synchronizer.sync_style</span></code> is not <code class="docutils literal notranslate"><span class="pre">fixed</span></code>) is used.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">ratio</span></code>: Explorer will only wait for <code class="docutils literal notranslate"><span class="pre">(1</span> <span class="pre">-</span> <span class="pre">ratio)</span> <span class="pre">*</span> <span class="pre">batch_size</span></code> of tasks at each step. Default is <code class="docutils literal notranslate"><span class="pre">0.0</span></code>, meaning waiting for all tasks.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">wait_after_min</span></code>: After reaching the minimum task threshold, wait for this many seconds before proceeding. Default is <code class="docutils literal notranslate"><span class="pre">30.0</span></code> seconds.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">dynamic_timeout</span></code>: [Experimental] Configurations for dynamic timeout mechanism, which adjusts the timeout for each task based on the average time taken for successful tasks.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">enable</span></code>: Whether to enable dynamic timeout. Default is <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ratio</span></code>: The timeout for each task is dynamically set to <code class="docutils literal notranslate"><span class="pre">average_time_per_success_task</span> <span class="pre">*</span> <span class="pre">ratio</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">3.0</span></code>.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">runner_state_report_interval</span></code>: Workflow runner report interval (in seconds). If set to a value greater than <code class="docutils literal notranslate"><span class="pre">0</span></code>, the workflow runner will periodically report its status to the main explorer process and print it in the command line for monitoring. Default is <code class="docutils literal notranslate"><span class="pre">0</span></code>, meaning this feature is disabled. If you want to use this feature, it is recommended to set it to <code class="docutils literal notranslate"><span class="pre">10</span></code> seconds or longer to minimize performance impact.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="synchronizer-configuration">
<h2>Synchronizer Configuration<a class="headerlink" href="#synchronizer-configuration" title="Link to this heading">#</a></h2>
<p>Controls how model weights are synchronized between trainer and explorer. Please refer to <a class="reference internal" href="synchronizer.html#synchronizer"><span class="std std-ref">Synchronizer in Trinity-RFT</span></a> for more details.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">synchronizer</span><span class="p">:</span>
<span class="w">  </span><span class="nt">sync_method</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;nccl&#39;</span>
<span class="w">  </span><span class="nt">sync_interval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="w">  </span><span class="nt">sync_offset</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">  </span><span class="nt">sync_timeout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1200</span>
<span class="w">  </span><span class="nt">sync_style</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;fixed&#39;</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sync_method</span></code>: Method of synchronization. Options:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">nccl</span></code>: Uses NCCL for fast synchronization. Supported for <code class="docutils literal notranslate"><span class="pre">both</span></code> mode.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">checkpoint</span></code>: Loads latest model from disk. Supported for <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">explore</span></code>, or <code class="docutils literal notranslate"><span class="pre">bench</span></code> mode.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sync_interval</span></code>: Interval (in steps) of model weight synchronization between trainer and explorer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sync_offset</span></code>: Offset (in steps) of model weight synchronization between trainer and explorer. The explorer can run <code class="docutils literal notranslate"><span class="pre">sync_offset</span></code> steps before the trainer starts training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sync_timeout</span></code>: Timeout duration for synchronization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sync_style</span></code>: Style of synchronization. Options:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fixed</span></code>: The explorer and trainer synchronize weights every <code class="docutils literal notranslate"><span class="pre">sync_interval</span></code> steps.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dynamic_by_explorer</span></code>: The explorer notifies the trainer to synchronize weights after completing <code class="docutils literal notranslate"><span class="pre">sync_interval</span></code> steps, regardless of how many steps the trainer has completed at this point.</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="trainer-configuration">
<h2>Trainer Configuration<a class="headerlink" href="#trainer-configuration" title="Link to this heading">#</a></h2>
<p>Specifies the backend and behavior of the trainer.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">trainer</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">trainer</span>
<span class="w">  </span><span class="nt">trainer_type</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;verl&quot;</span>
<span class="w">  </span><span class="nt">trainer_strategy</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;fsdp&quot;</span>
<span class="w">  </span><span class="nt">total_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000</span>
<span class="w">  </span><span class="nt">save_interval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100</span>
<span class="w">  </span><span class="nt">save_strategy</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;unrestricted&quot;</span>
<span class="w">  </span><span class="nt">save_hf_checkpoint</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;last&quot;</span>
<span class="w">  </span><span class="nt">grad_clip</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">  </span><span class="nt">use_dynamic_bsz</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">  </span><span class="nt">max_token_len_per_gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16384</span>
<span class="w">  </span><span class="nt">ulysses_sequence_parallel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">trainer_config</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: Name of the trainer. This name will be used as the Ray actor‚Äôs name, so it must be unique.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer_type</span></code>: Trainer backend implementation. Currently only supports <code class="docutils literal notranslate"><span class="pre">verl</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer_strategy</span></code>: Strategy for VeRL trainer. Default is <code class="docutils literal notranslate"><span class="pre">fsdp</span></code>. Options include:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fsdp</span></code>: Use PyTorch FSDP.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fsdp2</span></code>: Use PyTorch FSDP2.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">megatron</span></code>: Use Megatron-LM.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">total_steps</span></code>: Total number of training steps.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">save_interval</span></code>: Frequency (in steps) at which to save model checkpoints.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">save_strategy</span></code>: The parallel strategy used when saving the model. Defaults to <code class="docutils literal notranslate"><span class="pre">unrestricted</span></code>. The available options are as follows:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">single_thread</span></code>: Only one thread across the entire system is allowed to save the model; saving tasks from different threads are executed sequentially.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">single_process</span></code>: Only one process across the entire system is allowed to perform saving; multiple threads within that process can handle saving tasks in parallel, while saving operations across different processes are executed sequentially.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">single_node</span></code>: Only one compute node across the entire system is allowed to perform saving; processes and threads within that node can work in parallel, while saving operations across different nodes are executed sequentially.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">unrestricted</span></code>: No restrictions on saving operations; multiple nodes, processes, or threads are allowed to save the model simultaneously.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">save_hf_checkpoint</span></code>: Whether to save the model in HuggingFace format. Default is <code class="docutils literal notranslate"><span class="pre">last</span></code>. Note that saving in HuggingFace format consumes additional time, storage space, and GPU memory, which may impact training performance or lead to out-of-memory errors. Options include:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">last</span></code>: Save only the last checkpoint in HuggingFace format.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">always</span></code>: Save all checkpoints in HuggingFace format.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">never</span></code>: Do not save in HuggingFace format.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">grad_clip</span></code>: Gradient clipping for updates.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_dynamic_bsz</span></code>: Whether to use dynamic batch size.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_token_len_per_gpu</span></code>:  The maximum number of tokens to be processed in forward and backward when updating the policy. Effective when <code class="docutils literal notranslate"><span class="pre">use_dynamic_bsz=true</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ulysses_sequence_parallel_size</span></code>: Sequence parallel size.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer_config</span></code>: The trainer configuration provided inline.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="service-configuration">
<h2>Service Configuration<a class="headerlink" href="#service-configuration" title="Link to this heading">#</a></h2>
<p>Configures services used by Trinity-RFT. Only support Data Juicer service for now.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">service</span><span class="p">:</span>
<span class="w">  </span><span class="nt">data_juicer</span><span class="p">:</span>
<span class="w">    </span><span class="nt">server_url</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;http://127.0.0.1:5005&#39;</span>
<span class="w">    </span><span class="nt">auto_start</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5005</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">server_url</span></code>: The url of data juicer server.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">auto_start</span></code>: Whether to automatically start the data juicer service.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">port</span></code>: The port for Data Juicer service when <code class="docutils literal notranslate"><span class="pre">auto_start</span></code> is true.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="dataprocessor-configuration">
<h2>DataProcessor Configuration<a class="headerlink" href="#dataprocessor-configuration" title="Link to this heading">#</a></h2>
<p>Configures the task / experience pipeline, please refer to <a class="reference internal" href="example_data_functionalities.html#data-processing"><span class="std std-ref">Data Processing</span></a> section for details.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">data_processor</span><span class="p">:</span>
<span class="w">  </span><span class="nt">task_pipeline</span><span class="p">:</span>
<span class="w">    </span><span class="nt">num_process</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">32</span>
<span class="w">    </span><span class="nt">operators</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;llm_difficulty_score_filter&quot;</span>
<span class="w">        </span><span class="nt">args</span><span class="p">:</span>
<span class="w">          </span><span class="nt">api_or_hf_model</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;qwen2.5-7b-instruct&quot;</span>
<span class="w">          </span><span class="nt">min_score</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span>
<span class="w">          </span><span class="nt">input_keys</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">&quot;question&quot;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&quot;answer&quot;</span><span class="p p-Indicator">]</span>
<span class="w">          </span><span class="nt">field_names</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">&quot;Question&quot;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&quot;Answer&quot;</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="nt">inputs</span><span class="p">:</span><span class="w">  </span><span class="c1"># the output will be set to the explorer input automatically</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:TRINITY_TASKSET_PATH}</span>
<span class="w">    </span><span class="nt">target_fields</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">&quot;question&quot;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&quot;answer&quot;</span><span class="p p-Indicator">]</span>
<span class="w">  </span><span class="nt">experience_pipeline</span><span class="p">:</span>
<span class="w">    </span><span class="nt">operators</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">data_juicer</span>
<span class="w">        </span><span class="nt">args</span><span class="p">:</span>
<span class="w">          </span><span class="nt">config_path</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;examples/grpo_gsm8k_experience_pipeline/dj_scoring_exp.yaml&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">reward_shaping_mapper</span>
<span class="w">        </span><span class="nt">args</span><span class="p">:</span>
<span class="w">          </span><span class="nt">reward_shaping_configs</span><span class="p">:</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">stats_key</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;llm_quality_score&#39;</span>
<span class="w">              </span><span class="nt">op_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ADD</span>
<span class="w">              </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
</pre></div>
</div>
<p>‚Äì</p>
</section>
<section id="log-configuration">
<h2>Log Configuration<a class="headerlink" href="#log-configuration" title="Link to this heading">#</a></h2>
<p>Ray actor logging configuration.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">log</span><span class="p">:</span>
<span class="w">  </span><span class="nt">level</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">INFO</span>
<span class="w">  </span><span class="nt">group_by_node</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">level</span></code>: The logging level (supports <code class="docutils literal notranslate"><span class="pre">DEBUG</span></code>, <code class="docutils literal notranslate"><span class="pre">INFO</span></code>, <code class="docutils literal notranslate"><span class="pre">WARNING</span></code>, <code class="docutils literal notranslate"><span class="pre">ERROR</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">group_by_node</span></code>: Whether to group logs by node IP. If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, an actor‚Äôs logs will be save to <code class="docutils literal notranslate"><span class="pre">&lt;checkpoint_root_dir&gt;/&lt;project&gt;/&lt;name&gt;/log/&lt;node_ip&gt;/&lt;actor_name&gt;.log</span></code>, otherwise it will be saved to <code class="docutils literal notranslate"><span class="pre">&lt;checkpoint_root_dir&gt;/&lt;project&gt;/&lt;name&gt;/log/&lt;actor_name&gt;.log</span></code>.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="stages-configuration">
<h2>Stages Configuration<a class="headerlink" href="#stages-configuration" title="Link to this heading">#</a></h2>
<p>For multi-stage training, you can define multiple stages in the <code class="docutils literal notranslate"><span class="pre">stages</span></code> field. Each stage can have its own <code class="docutils literal notranslate"><span class="pre">algorithm</span></code>, <code class="docutils literal notranslate"><span class="pre">buffer</span></code> and other configurations. If a parameter is not specified in a stage, it will inherit the value from the global configuration. Multiple stages will be executed sequentially as defined.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">stages</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">stage_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sft_warmup</span>
<span class="w">    </span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">train</span>
<span class="w">    </span><span class="nt">algorithm</span><span class="p">:</span>
<span class="w">      </span><span class="nt">algorithm_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sft</span>
<span class="w">    </span><span class="nt">buffer</span><span class="p">:</span>
<span class="w">      </span><span class="nt">train_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">64</span>
<span class="w">      </span><span class="nt">total_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100</span>
<span class="w">      </span><span class="nt">trainer_input</span><span class="p">:</span>
<span class="w">        </span><span class="nt">experience_buffer</span><span class="p">:</span>
<span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sft_buffer</span>
<span class="w">          </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:TRINITY_DATASET_PATH}</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">stage_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rft</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">stage_name</span></code>: Name of the stage. It should be unique and will be used as a suffix for the experiment name.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mode</span></code>: Running mode of Trinity-RFT for this stage. If not specified, it will inherit from the global <code class="docutils literal notranslate"><span class="pre">mode</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">algorithm</span></code>: Algorithm configuration for this stage. If not specified, it will inherit from the global <code class="docutils literal notranslate"><span class="pre">algorithm</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">buffer</span></code>: Buffer configuration for this stage. If not specified, it will inherit from the global <code class="docutils literal notranslate"><span class="pre">buffer</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">explorer</span></code>: Explorer configuration for this stage. If not specified, it will inherit from the global <code class="docutils literal notranslate"><span class="pre">explorer</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer</span></code>: Trainer configuration for this stage. If not specified, it will inherit from the global <code class="docutils literal notranslate"><span class="pre">trainer</span></code>.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="verl-trainer-configuration-advanced">
<h2>veRL Trainer Configuration (Advanced)<a class="headerlink" href="#verl-trainer-configuration-advanced" title="Link to this heading">#</a></h2>
<p>For advanced users working with the <code class="docutils literal notranslate"><span class="pre">verl</span></code> trainer backend. This includes fine-grained settings for actor/critic models, optimizer parameters, and training loops.</p>
<blockquote>
<div><p>For full parameter meanings, refer to the <a class="reference external" href="https://verl.readthedocs.io/en/latest/examples/config.html">veRL documentation</a>.</p>
</div></blockquote>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">actor_rollout_ref</span><span class="p">:</span>
<span class="w">  </span><span class="nt">hybrid_engine</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">  </span><span class="nt">model</span><span class="p">:</span>
<span class="w">    </span><span class="nt">external_lib</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">override_config</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{</span><span class="w"> </span><span class="p p-Indicator">}</span>
<span class="w">    </span><span class="nt">enable_gradient_checkpointing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">    </span><span class="nt">use_remove_padding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">    </span><span class="nt">use_fused_kernels</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">    </span><span class="nt">fused_kernel_options</span><span class="p">:</span>
<span class="w">      </span><span class="nt">impl_backend</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">None</span>
<span class="w">  </span><span class="nt">actor</span><span class="p">:</span>
<span class="w">    </span><span class="nt">strategy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fsdp</span><span class="w">  </span><span class="c1"># This is for backward-compatibility</span>
<span class="w">    </span><span class="c1"># ppo_micro_batch_size: 8 # will be deprecated, use ppo_micro_batch_size_per_gpu</span>
<span class="w">    </span><span class="nt">ppo_micro_batch_size_per_gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">    </span><span class="nt">use_dynamic_bsz</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">    </span><span class="nt">ppo_max_token_len_per_gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16384</span><span class="w"> </span><span class="c1"># n * ${data.max_model_len}</span>
<span class="w">    </span><span class="nt">grad_clip</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">    </span><span class="nt">ppo_epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">shuffle</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">    </span><span class="nt">ulysses_sequence_parallel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># sp size</span>
<span class="w">    </span><span class="nt">entropy_from_logits_with_chunking</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">entropy_checkpointing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">checkpoint</span><span class="p">:</span>
<span class="w">      </span><span class="nt">load_contents</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">&#39;model&#39;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&#39;optimizer&#39;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&#39;extra&#39;</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">save_contents</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">&#39;model&#39;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&#39;optimizer&#39;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&#39;extra&#39;</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="nt">optim</span><span class="p">:</span>
<span class="w">      </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-6</span>
<span class="w">      </span><span class="nt">lr_warmup_steps_ratio</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.</span><span class="w">  </span><span class="c1"># the total steps will be injected during runtime</span>
<span class="w">      </span><span class="c1"># min_lr_ratio: null   # only useful for warmup with cosine</span>
<span class="w">      </span><span class="nt">warmup_style</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">constant</span><span class="w">  </span><span class="c1"># select from constant/cosine</span>
<span class="w">      </span><span class="nt">total_training_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-1</span><span class="w">  </span><span class="c1"># must be override by program</span>
<span class="w">    </span><span class="nt">fsdp_config</span><span class="p">:</span>
<span class="w">      </span><span class="nt">wrap_policy</span><span class="p">:</span>
<span class="w">        </span><span class="c1"># transformer_layer_cls_to_wrap: None</span>
<span class="w">        </span><span class="nt">min_num_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">      </span><span class="nt">param_offload</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">      </span><span class="nt">optimizer_offload</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">      </span><span class="nt">fsdp_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-1</span>
<span class="w">      </span><span class="nt">forward_prefetch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">  </span><span class="nt">ref</span><span class="p">:</span>
<span class="w">    </span><span class="nt">fsdp_config</span><span class="p">:</span>
<span class="w">      </span><span class="nt">param_offload</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">      </span><span class="nt">wrap_policy</span><span class="p">:</span>
<span class="w">        </span><span class="c1"># transformer_layer_cls_to_wrap: None</span>
<span class="w">        </span><span class="nt">min_num_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">      </span><span class="nt">fsdp_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-1</span>
<span class="w">      </span><span class="nt">forward_prefetch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">    </span><span class="c1"># log_prob_micro_batch_size: 4 # will be deprecated, use log_prob_micro_batch_size_per_gpu</span>
<span class="w">    </span><span class="nt">log_prob_micro_batch_size_per_gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">    </span><span class="nt">log_prob_use_dynamic_bsz</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${actor_rollout_ref.actor.use_dynamic_bsz}</span>
<span class="w">    </span><span class="nt">log_prob_max_token_len_per_gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${actor_rollout_ref.actor.ppo_max_token_len_per_gpu}</span>
<span class="w">    </span><span class="nt">ulysses_sequence_parallel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${actor_rollout_ref.actor.ulysses_sequence_parallel_size}</span><span class="w"> </span><span class="c1"># sp size</span>
<span class="w">    </span><span class="nt">entropy_from_logits_with_chunking</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${actor_rollout_ref.actor.entropy_from_logits_with_chunking}</span>
<span class="w">    </span><span class="nt">entropy_checkpointing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${actor_rollout_ref.actor.entropy_checkpointing}</span>

<span class="nt">critic</span><span class="p">:</span>
<span class="w">  </span><span class="nt">strategy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fsdp</span>
<span class="w">  </span><span class="nt">optim</span><span class="p">:</span>
<span class="w">    </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-5</span>
<span class="w">    </span><span class="nt">lr_warmup_steps_ratio</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.</span><span class="w">  </span><span class="c1"># the total steps will be injected during runtime</span>
<span class="w">    </span><span class="c1"># min_lr_ratio: null   # only useful for warmup with cosine</span>
<span class="w">    </span><span class="nt">warmup_style</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">constant</span><span class="w">  </span><span class="c1"># select from constant/cosine</span>
<span class="w">    </span><span class="nt">total_training_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-1</span><span class="w">  </span><span class="c1"># must be override by program</span>
<span class="w">  </span><span class="nt">model</span><span class="p">:</span>
<span class="w">    </span><span class="nt">override_config</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{</span><span class="w"> </span><span class="p p-Indicator">}</span>
<span class="w">    </span><span class="nt">external_lib</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${actor_rollout_ref.model.external_lib}</span>
<span class="w">    </span><span class="nt">enable_gradient_checkpointing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">    </span><span class="nt">use_remove_padding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">    </span><span class="nt">fsdp_config</span><span class="p">:</span>
<span class="w">      </span><span class="nt">param_offload</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">      </span><span class="nt">optimizer_offload</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">      </span><span class="nt">wrap_policy</span><span class="p">:</span>
<span class="w">        </span><span class="c1"># transformer_layer_cls_to_wrap: None</span>
<span class="w">        </span><span class="nt">min_num_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">      </span><span class="nt">fsdp_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-1</span>
<span class="w">      </span><span class="nt">forward_prefetch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">  </span><span class="nt">ppo_micro_batch_size_per_gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">  </span><span class="nt">forward_micro_batch_size_per_gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${critic.ppo_micro_batch_size_per_gpu}</span>
<span class="w">  </span><span class="nt">use_dynamic_bsz</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${actor_rollout_ref.actor.use_dynamic_bsz}</span>
<span class="w">  </span><span class="nt">ppo_max_token_len_per_gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">32768</span><span class="w"> </span><span class="c1"># (${actor_rollout_ref.actor.ppo_max_token_len_per_gpu}) * 2</span>
<span class="w">  </span><span class="nt">forward_max_token_len_per_gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${critic.ppo_max_token_len_per_gpu}</span>
<span class="w">  </span><span class="nt">ulysses_sequence_parallel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># sp size</span>
<span class="w">  </span><span class="nt">ppo_epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${actor_rollout_ref.actor.ppo_epochs}</span>
<span class="w">  </span><span class="nt">shuffle</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${actor_rollout_ref.actor.shuffle}</span>
<span class="w">  </span><span class="nt">grad_clip</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">  </span><span class="nt">cliprange_value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.5</span>

<span class="nt">trainer</span><span class="p">:</span>
<span class="w">  </span><span class="nt">balance_batch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">  </span><span class="c1"># total_training_steps: null</span>
<span class="w">  </span><span class="nt">resume_mode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">auto</span>
<span class="w">  </span><span class="nt">resume_from_path</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&quot;</span>
<span class="w">  </span><span class="nt">critic_warmup</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">  </span><span class="nt">default_hdfs_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">  </span><span class="nt">remove_previous_ckpt_in_save</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">  </span><span class="nt">del_local_ckpt_after_load</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">  </span><span class="nt">max_actor_ckpt_to_keep</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="w">  </span><span class="nt">max_critic_ckpt_to_keep</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.model.enable_gradient_checkpointing</span></code>: Whether to enable gradient checkpointing, which will reduce GPU memory usage.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.model.use_remove_padding</span></code>: Whether to remove pad tokens, which will reduce training time.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.model.use_fused_kernels</span></code>: Whether to use custom fused kernels (e.g., FlashAttention, fused MLP).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.model.fused_kernel_options.impl_backend</span></code>: Implementation backend for fused kernels. If use_fused_kernels is true, this will be used. Options: ‚Äútriton‚Äù or ‚Äútorch‚Äù.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.use_dynamic_bsz</span></code>: Whether to reorganize the batch data, specifically to splice the shorter data to reduce the batch size in the actual training process.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu</span></code>: Batch size for one GPU in one forward pass.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.ulysses_sequence_parallel_size</span></code>: Ulysses sequence parallel size.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.entropy_from_logits_with_chunking</span></code>: Calculate entropy with chunking to reduce memory peak.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.entropy_checkpointing</span></code>: Recompute entropy.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.checkpoint</span></code>: Contents to be loaded and saved. With ‚Äòhf_model‚Äô you can save whole model as hf format; now only use sharded model checkpoint to save space.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.optim.lr</span></code>: Learning rate for actor model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.optim.lr_warmup_steps_ratio</span></code>: Ratio of warmup steps for learning rate.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.optim.warmup_style</span></code>: Warmup style for learning rate.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.actor.optim.total_training_steps</span></code>: Total training steps for actor model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu</span></code>: Batch size for one GPU in one reference model forward pass.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">critic.model.enable_gradient_checkpointing</span></code>: Whether to enable gradient checkpointing, which will reduce GPU memory usage.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">critic.model.use_remove_padding</span></code>: Whether to remove pad tokens, which will reduce training time.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">critic.optim.lr</span></code>: Learning rate for critic model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">critic.optim.lr_warmup_steps_ratio</span></code>: Ratio of warmup steps for learning rate.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">critic.optim.warmup_style</span></code>: Warmup style for learning rate.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">critic.optim.total_training_steps</span></code>: Total training steps for critic model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">critic.ppo_micro_batch_size_per_gpu</span></code>: Batch size for one GPU in one critic model forward pass.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">critic.ulysses_sequence_parallel_size</span></code>: Ulysses sequence parallel size.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">critic.grad_clip</span></code>: Gradient clip for critic model training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">critic.cliprange_value</span></code>: Used for compute value loss.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.balance_batch</span></code>: Whether to balance batch size between GPUs during training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.resume_mode</span></code>: Resume mode for training. Support <code class="docutils literal notranslate"><span class="pre">disable</span></code>, <code class="docutils literal notranslate"><span class="pre">auto</span></code> and <code class="docutils literal notranslate"><span class="pre">resume_path</span></code>. Default value is <code class="docutils literal notranslate"><span class="pre">auto</span></code>, i.e., finding the last ckpt to resume or training from scratch when it cannot find the ckpt.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.resume_from_path</span></code>: Path to resume from.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.critic_warmup</span></code>: The number of steps to train the critic model before actual policy learning.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.default_hdfs_dir</span></code>: Default HDFS directory for saving checkpoints.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.remove_previous_ckpt_in_save</span></code>: Whether to remove previous checkpoints in save.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.del_local_ckpt_after_load</span></code>: Whether to delete local checkpoints after loading.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.max_actor_ckpt_to_keep</span></code>: Maximum number of actor checkpoints to keep.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer.max_critic_ckpt_to_keep</span></code>: Maximum number of critic checkpoints to keep.</p></li>
</ul>
</section>
<section id="adding-new-config-entries-for-the-config-generator-advanced">
<h2>Adding New Config Entries for the Config Generator (Advanced)<a class="headerlink" href="#adding-new-config-entries-for-the-config-generator-advanced" title="Link to this heading">#</a></h2>
<p>This section introduces how to add new configuration parameters to the Config Generator page of Trinity-RFT.</p>
<section id="step-0-understanding-streamlit">
<h3>Step 0: Understanding Streamlit<a class="headerlink" href="#step-0-understanding-streamlit" title="Link to this heading">#</a></h3>
<p>Before adding new parameters to the Config Generator page, it is essential to familiarize yourself with the relevant API and mechanisms of <a class="reference external" href="https://docs.streamlit.io/develop/api-reference">Streamlit</a>. This project primarily utilizes various input components from Streamlit and employs <code class="docutils literal notranslate"><span class="pre">st.session_state</span></code> to store user-input parameters.</p>
</section>
<section id="step-1-implement-new-config-entries">
<h3>Step 1: Implement New Config Entries<a class="headerlink" href="#step-1-implement-new-config-entries" title="Link to this heading">#</a></h3>
<p>To illustrate the process of creating a new parameter setting for the Config Generator page, we will use <code class="docutils literal notranslate"><span class="pre">train_batch_size</span></code> as an example.</p>
<ol class="arabic">
<li><p>Determine the appropriate scope for the parameter. Currently, parameters are categorized into four files:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">trinity/manager/config_registry/buffer_config_manager.py</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trinity/manager/config_registry/explorer_config_manager.py</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trinity/manager/config_registry/model_config_manager.py</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trinity/manager/config_registry/trainer_config_manager.py</span></code></p></li>
</ul>
<p>In this case, <code class="docutils literal notranslate"><span class="pre">train_batch_size</span></code> should be placed in the <code class="docutils literal notranslate"><span class="pre">buffer_config_manager.py</span></code> file.</p>
</li>
<li><p>Create a parameter setting function using Streamlit. The function name must follow the convention of starting with ‚Äòset_‚Äô, and the remainder of the name becomes the config name.</p></li>
<li><p>Decorate the parameter setting function with the <code class="docutils literal notranslate"><span class="pre">CONFIG_GENERATORS.register_config</span></code> decorator. This decorator requires the following information:</p>
<ul class="simple">
<li><p>Default value of the parameter</p></li>
<li><p>Visibility condition (if applicable)</p></li>
<li><p>Additional config parameters (if needed)</p></li>
</ul>
</li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">CONFIG_GENERATORS.register_config</span></code> decorator automatically passes <code class="docutils literal notranslate"><span class="pre">key=config_name</span></code> as an argument to the registered configuration function. Ensure that your function accepts this keyword argument.</p>
</div>
<p>For <code class="docutils literal notranslate"><span class="pre">train_batch_size</span></code>, we will use the following settings:</p>
<ul class="simple">
<li><p>Default value: 96</p></li>
<li><p>Visibility condition: <code class="docutils literal notranslate"><span class="pre">lambda:</span> <span class="pre">st.session_state[&quot;trainer_gpu_num&quot;]</span> <span class="pre">&gt;</span> <span class="pre">0</span></code></p></li>
<li><p>Additional config: <code class="docutils literal notranslate"><span class="pre">{&quot;_train_batch_size_per_gpu&quot;:</span> <span class="pre">16}</span></code></p></li>
</ul>
<p>Here‚Äôs the complete code for the <code class="docutils literal notranslate"><span class="pre">train_batch_size</span></code> parameter:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@CONFIG_GENERATORS</span><span class="o">.</span><span class="n">register_config</span><span class="p">(</span>
    <span class="n">default_value</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span>
    <span class="n">visible</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="p">[</span><span class="s2">&quot;trainer_gpu_num&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">other_configs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;_train_batch_size_per_gpu&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">},</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">set_train_batch_size</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">key</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">)</span>
    <span class="n">trainer_gpu_num</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="p">[</span><span class="s2">&quot;trainer_gpu_num&quot;</span><span class="p">]</span>
    <span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="p">[</span><span class="s2">&quot;_train_batch_size_per_gpu&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="p">[</span><span class="s2">&quot;trainer_gpu_num&quot;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_change</span><span class="p">():</span>
        <span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="p">[</span><span class="s2">&quot;_train_batch_size_per_gpu&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
            <span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">//</span> <span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="p">[</span><span class="s2">&quot;trainer_gpu_num&quot;</span><span class="p">],</span> <span class="mi">1</span>
        <span class="p">)</span>

    <span class="n">st</span><span class="o">.</span><span class="n">number_input</span><span class="p">(</span>
        <span class="s2">&quot;Train Batch Size&quot;</span><span class="p">,</span>
        <span class="n">min_value</span><span class="o">=</span><span class="n">trainer_gpu_num</span><span class="p">,</span>
        <span class="n">step</span><span class="o">=</span><span class="n">trainer_gpu_num</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="n">_str_for_train_batch_size</span><span class="p">(),</span>
        <span class="n">on_change</span><span class="o">=</span><span class="n">on_change</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>If the parameter requires validation, create a check function. For <code class="docutils literal notranslate"><span class="pre">train_batch_size</span></code>, we need to ensure it is divisible by <code class="docutils literal notranslate"><span class="pre">trainer_gpu_num</span></code>. If not, a warning should be displayed, and the parameter should be added to <code class="docutils literal notranslate"><span class="pre">unfinished_fields</span></code>.</p>
<p>Decorate the check function with the <code class="docutils literal notranslate"><span class="pre">CONFIG_GENERATORS.register_check</span></code> decorator:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@CONFIG_GENERATORS</span><span class="o">.</span><span class="n">register_check</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">check_train_batch_size</span><span class="p">(</span><span class="n">unfinished_fields</span><span class="p">:</span> <span class="nb">set</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">%</span> <span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="p">[</span><span class="s2">&quot;trainer_gpu_num&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">unfinished_fields</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="n">st</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">_str_for_train_batch_size</span><span class="p">())</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">CONFIG_GENERATORS.register_check</span></code> decorator automatically receives <code class="docutils literal notranslate"><span class="pre">key=config_name</span></code> and <code class="docutils literal notranslate"><span class="pre">unfinished_fields=self.unfinished_fields</span></code> as arguments. Ensure your function accepts these keyword arguments.</p>
</div>
</section>
<section id="step-2-integrating-new-parameters-into-config-manager-py">
<h3>Step 2: Integrating New Parameters into <code class="docutils literal notranslate"><span class="pre">config_manager.py</span></code><a class="headerlink" href="#step-2-integrating-new-parameters-into-config-manager-py" title="Link to this heading">#</a></h3>
<p>To successfully integrate new parameters into the <code class="docutils literal notranslate"><span class="pre">config_manager.py</span></code> file, please adhere to the following procedure:</p>
<ol class="arabic">
<li><p>Parameter Categorization:
Determine the appropriate section for the new parameter based on its functionality. The config generator page is structured into two primary modes:</p>
<ul class="simple">
<li><p>Beginner Mode: Comprises ‚ÄúEssential Configs‚Äù and ‚ÄúImportant Configs‚Äù sections.</p></li>
<li><p>Expert Mode: Includes ‚ÄúModel‚Äù, ‚ÄúBuffer‚Äù, ‚ÄúExplorer and Synchronizer‚Äù, and ‚ÄúTrainer‚Äù sections.</p></li>
</ul>
</li>
<li><p>Parameter Addition:
Incorporate the new parameter into the relevant section using the <code class="docutils literal notranslate"><span class="pre">self.get_configs</span></code> method within the <code class="docutils literal notranslate"><span class="pre">ConfigManager</span></code> class.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ConfigManager</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_expert_buffer_part</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">get_configs</span><span class="p">(</span><span class="s2">&quot;total_epochs&quot;</span><span class="p">,</span> <span class="s2">&quot;train_batch_size&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>YAML File Integration:
Locate the appropriate position for the new parameter within the YAML file structure. This should be done in the <code class="docutils literal notranslate"><span class="pre">generate_config</span></code> function and its associated sub-functions.</p></li>
<li><p>Parameter Value Assignment:
Utilize <code class="docutils literal notranslate"><span class="pre">st.session_state</span></code> to retrieve the parameter value from the config generator page and assign it to the corresponding field in the YAML.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ConfigManager</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_gen_buffer_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">buffer_config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">st</span><span class="o">.</span><span class="n">session_state</span><span class="p">[</span><span class="s2">&quot;train_batch_size&quot;</span><span class="p">],</span>
            <span class="c1"># Additional configuration parameters</span>
        <span class="p">}</span>
</pre></div>
</div>
</li>
</ol>
<p>By following these steps, you can successfully add new parameters to the Config Generator page and ensure they are properly integrated into the configuration management system.</p>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="develop_selector.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">üß™ Experimental: Task Selection</p>
      </div>
    </a>
    <a class="right-next"
       href="trinity_gpu_configs.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">GPU Configuration Guide</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#global-configuration">Global Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithm-configuration">Algorithm Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monitor-configuration">Monitor Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-configuration">Model Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cluster-configuration">Cluster Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#buffer-configuration">Buffer Configuration</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explorer-input">Explorer Input</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#trainer-input">Trainer Input</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#explorer-configuration">Explorer Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#synchronizer-configuration">Synchronizer Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trainer-configuration">Trainer Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#service-configuration">Service Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataprocessor-configuration">DataProcessor Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#log-configuration">Log Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stages-configuration">Stages Configuration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#verl-trainer-configuration-advanced">veRL Trainer Configuration (Advanced)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-new-config-entries-for-the-config-generator-advanced">Adding New Config Entries for the Config Generator (Advanced)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-0-understanding-streamlit">Step 0: Understanding Streamlit</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-implement-new-config-entries">Step 1: Implement New Config Entries</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-integrating-new-parameters-into-config-manager-py">Step 2: Integrating New Parameters into <code class="docutils literal notranslate"><span class="pre">config_manager.py</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Trinity-RFT Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2025, Trinity-RFT Team.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>